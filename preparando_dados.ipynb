{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyi0yibBmtBgi8wM4Lmeqp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FabioWilliam/imersao-ia-gemini/blob/main/preparando_dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MK-u6uLRm7Lm"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "api_key =userdata.get('API_KEY')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalando a biblioteca do Generativeai"
      ],
      "metadata": {
        "id": "dK20AUry9oTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "9N8ewZ8f9XXl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando a biblioteca do generativeai"
      ],
      "metadata": {
        "id": "NkMSwrCX-rP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "VKr20fMT9xif"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurando o api da chamada para o genai"
      ],
      "metadata": {
        "id": "FQsWzin8_QxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=api_key)"
      ],
      "metadata": {
        "id": "VVRwr9Nf_QQS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listar os modelos dispon√≠ves"
      ],
      "metadata": {
        "id": "vPod9iyD_p5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in genai.list_models():\n",
        "    if 'generateContent' in i.supported_generation_methods:\n",
        "      print(i.name, '|', i.display_name,'|', i.description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "C26j6c2E_tj4",
        "outputId": "8870d40d-b327-4a90-e79c-c5131ab94a65"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro | Gemini 1.0 Pro | The best model for scaling across a wide range of tasks\n",
            "models/gemini-1.0-pro-001 | Gemini 1.0 Pro 001 (Tuning) | The best model for scaling across a wide range of tasks. This is a stable model that supports tuning.\n",
            "models/gemini-1.0-pro-latest | Gemini 1.0 Pro Latest | The best model for scaling across a wide range of tasks. This is the latest model.\n",
            "models/gemini-1.0-pro-vision-latest | Gemini 1.0 Pro Vision | The best image understanding model to handle a broad range of applications\n",
            "models/gemini-1.5-pro-latest | Gemini 1.5 Pro | Mid-size multimodal model that supports up to 1 million tokens\n",
            "models/gemini-pro | Gemini 1.0 Pro | The best model for scaling across a wide range of tasks\n",
            "models/gemini-pro-vision | Gemini 1.0 Pro Vision | The best image understanding model to handle a broad range of applications\n"
          ]
        }
      ]
    }
  ]
}